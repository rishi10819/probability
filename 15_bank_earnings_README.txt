Say you manage a bank that gives out 10,000 loans. 
The default rate is 0.03 and you lose $200,000 in each foreclosure.
Create a random variable S that contains the earnings of your bank. 
Calculate the total amount of money lost in this scenario.

-----------------------------------

Run a Monte Carlo simulation with 10,000 outcomes for S, the sum of losses over 10,000 loans. 
Make a histogram of the results.

-----------------------------------

What is the expected value of S, the sum of losses over 10,000 loans? 

-----------------------------------

What is the standard error of S?

-----------------------------------

So far, we've been assuming that we make no money when people pay their loans and we lose a lot of money when people default on their loans. 
Assume we give out loans for $180,000. 
How much money do we need to make when people pay their loans so that our net loss is $0?
In other words, what interest rate do we need to charge in order to not lose money?

-----------------------------------

With the interest rate just calculated, we still lose money 50% of the time. 
What should the interest rate be so that the chance of losing money is 1 in 20? 
In math notation, what should the interest rate be so that 
Pr(S<0)=0.05?

-----------------------------------